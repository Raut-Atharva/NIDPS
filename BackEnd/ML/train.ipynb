{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\atharva\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\atharva\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm) (1.14.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # type: ignore\n",
    "import lightgbm as lgb  # type: ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_df = pd.read_csv('data/UNSW_NB15_training.csv')\n",
    "test_df = pd.read_csv('data/Book1.csv')\n",
    "\n",
    "print(lgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', \n",
    "            'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'swin', 'dwin', \n",
    "            'is_sm_ips_ports']\n",
    "target = 'attack_cat_number'  # Adjust if your target column has a different name\n",
    "\n",
    "# Identify categorical features\n",
    "cat_features = ['proto', 'service', 'state']\n",
    "for col in cat_features:\n",
    "    train_df[col] = train_df[col].astype('category')\n",
    "    test_df[col] = test_df[col].astype('category')\n",
    "\n",
    "# Split into X (features) and y (labels)\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test, y_test = test_df[features], test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)\n",
    "test_data = lgb.Dataset(X_test, label=y_test, categorical_feature=cat_features)\n",
    "\n",
    "# Define model parameters\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_class': 10,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Train model\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=200,  # Ensure this is before early stopping\n",
    "    valid_sets=[test_data],\n",
    "    valid_names=[\"validation\"],  # Give validation set a name\n",
    "    # early_stopping_rounds=50  # This should be placed after valid_sets\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
